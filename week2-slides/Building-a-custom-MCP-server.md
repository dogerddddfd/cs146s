这份PPT是斯坦福大学2025年秋季课程**CS146S《现代软件开发人员》（The Modern Software Developer）**的讲义，由Mihail Eric授课。本次课程的主题是**“走向MCP及其未来”（To MCP and Beyond）**，重点介绍了**模型上下文协议（Model Context Protocol, MCP）**。

以下是本次课程内容的详细总结：

### 1. 为什么需要MCP？
*   **大模型的局限性：** LLM 拥有庞大但**静态**的世界知识，只有通过重新训练才能更新。
*   **动态数据的需求：** 构建全自动系统需要稳健的方法来获取动态数据（如天气、股价、新闻等），目前最佳的解决方案是**检索增强生成（RAG）和工具调用（tool-calling）**。
*   **集成挑战：** 在没有标准协议的情况下，将多种 LLM 应用与多种第三方 API 集成会产生极其复杂的 **$M \times N$ 连接问题**，开发者必须为每个集成重复实现身份验证、错误处理和限流。

### 2. MCP 的基本定义与优势
*   **定义：** **MCP（Model Context Protocol）**是一种开放协议，允许系统以一种跨集成通用的方式为 AI 模型提供上下文。
*   **核心优势：**
    *   **简化集成：** 将连接复杂度从 $M \times N$ 降低到 **$M + N$**。
    *   **标准化：** 使用 **JSON-RPC** 强制执行一致的输出格式，无需为每个工具重新实现基础逻辑。
    *   **主动工作流：** 它扩展自语言服务器协议（LSP），支持主动的智能体工作流，而不仅仅是被动响应。

### 3. MCP 架构与核心术语
MCP 的运作涉及四个关键角色：
*   **宿主（Host）：** 运行 AI 应用的平台，如 **Cursor** 或 **Claude Desktop**。
*   **MCP 客户端（MCP Client）：** 嵌入在宿主中的库，负责与服务器维持会话。
*   **MCP 服务器（MCP Server）：** 位于工具前端的轻量级包装器。
*   **工具（Tool）：** 可调用的功能，可以是数据源或 API。

### 4. 工作流程（Workflow）
1.  **查询工具：** 客户端向 MCP 服务器询问“你能做什么？”。
2.  **返回描述：** 服务器返回描述每个工具的 JSON 架构（包含名称、摘要和参数模式）。
3.  **注入上下文：** 宿主将这些 JSON 描述注入模型的上下文窗口。
4.  **触发调用：** 用户提示触发模型生成结构化的工具调用请求。
5.  **执行并响应：** MCP 服务器执行该工具，将结果返回给对话，LLM 随后完成最终回复。

### 5. 当前的局限性
*   **工具处理能力：** 目前的智能体在处理大量工具时表现仍然欠佳。
*   **上下文消耗：** API 的描述信息会迅速消耗模型的**上下文窗口**。
*   **设计挑战：** 开发者应当设计**AI 原生（AI-native）**的 API，而不是死板的传统接口。

课程最后鼓励学生尝试**从零开始构建自定义的 MCP 服务器**，以实践人机协作工程的核心理念。